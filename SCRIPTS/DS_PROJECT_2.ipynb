{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RainaVardhan/DS4002-Project-2/blob/main/SCRIPTS/DS_PROJECT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/RainaVardhan/DS4002-Project-2.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyPi5zdVqMgh",
        "outputId": "28b09323-ec8e-4c95-dbeb-f588e36b55b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DS4002-Project-2'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 115 (delta 50), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (115/115), 2.69 MiB | 4.43 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a_gvT2pUtStU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset from CSV file\n",
        "df = pd.read_csv('/content/DS4002-Project-2/DATA/1950-2023_all_tornadoes.csv')\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "wnMq4pq-tcRZ",
        "outputId": "95fba17b-3272-49c1-8d41-77237464d2f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/DS4002-Project-2/DATA/1950-2023_all_tornadoes (3).csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a171d89cb4e9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Loading the dataset from CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/DS4002-Project-2/DATA/1950-2023_all_tornadoes (3).csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/DS4002-Project-2/DATA/1950-2023_all_tornadoes (3).csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert date to datetime and filtered for Minnesota state\n",
        "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
        "mn_df = df[df['st'] == 'MN']\n",
        "mn_df['loss']"
      ],
      "metadata": {
        "id": "8IECsRLqAi_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new column using dictionary\n",
        "mapping = {1.0: 50, 2.0: 300, 3.0: 3000, 4.0: 30000, 5.0: 300000, 6.0: 3000000,\n",
        "           7.0: 30000000, 8.0: 300000000, 9.0: 5000000000}\n",
        "\n",
        "# combine this new data with existing DataFrame\n",
        "mn_df['loss'] = mn_df['loss'].map(mapping).fillna(mn_df['loss'])\n",
        "mn_df['loss'] = mn_df['loss'] != 0\n",
        "mn_df"
      ],
      "metadata": {
        "id": "DMA3baZzEj8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Group data by year and aggregate by property loss, crop loss, and tornado frequency\n",
        "yearly_data = mn_df.groupby(mn_df['date'].dt.year).agg({\n",
        "    'loss': 'sum',\n",
        "    'om': 'count'\n",
        "}).reset_index()\n",
        "\n",
        "yearly_data.rename(columns={'om': 'num_tornadoes'}, inplace=True)\n",
        "yearly_data"
      ],
      "metadata": {
        "id": "82aWuZ1sGP65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for null values\n",
        "yearly_data.info()"
      ],
      "metadata": {
        "id": "zNcZFhTFIE_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(2, 1, figsize=(10, 8))\n",
        "\n",
        "#Plot the number of tornadoes each year\n",
        "yearly_data['num_tornadoes'].plot(ax=ax[0], title='Number of Tornadoes in Minnesota', color='blue')\n",
        "ax[0].set_ylabel('Number of Tornadoes')\n",
        "\n",
        "#Plot the property damage each year\n",
        "yearly_data['loss'].plot(ax=ax[1], title='Property Damage (in millions)', color='green')\n",
        "ax[1].set_ylabel('Property Damage')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PgkRsWjhGei1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform ADF test to check for stationary of tornado data\n",
        "result = adfuller(yearly_data['num_tornadoes'])\n",
        "print(f\"ADF Statistic for Number of Tornadoes: {result[0]}\")\n",
        "print(f\"p-value: {result[1]}\")"
      ],
      "metadata": {
        "id": "B1zSLTGpGpYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying differencing if series is non-stationary (p-value > 0.05)\n",
        "if result[1] > 0.05:\n",
        "    yearly_data['num_tornadoes_diff'] = yearly_data['num_tornadoes'].diff().dropna()\n",
        "    result = adfuller(yearly_data['num_tornadoes_diff'])\n",
        "    stationarity_interpretation = \"Stationary\" if result[1] < 0.05 else \"Non-Stationary\"\n",
        "\n",
        "else:\n",
        "    yearly_data['num_tornadoes_diff'] = yearly_data['num_tornadoes']\n",
        "    stationarity_interpretation = \"Stationary\"\n",
        "\n",
        "print(f\"ADF Statistic after differencing: {result[0]}\")\n",
        "print(f\"p-value after differencing: {result[1]}\")\n",
        "print(f\"Interpretation: The series is {stationarity_interpretation}.\")"
      ],
      "metadata": {
        "id": "28GcUoJ4Gqdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_lags = min(40, len(yearly_data['num_tornadoes']) // 2)\n",
        "fig, ax = plt.subplots(2, figsize=(12, 8))\n",
        "\n",
        "#ACF plot to find 'q' (moving average term)\n",
        "plot_acf(yearly_data['num_tornadoes'], lags=max_lags, ax=ax[0])\n",
        "ax[0].set_title('ACF Plot (Number of Tornadoes)')\n",
        "\n",
        "#PACF plot to find 'p' (autoregressive term)\n",
        "plot_pacf(yearly_data['num_tornadoes'], lags=max_lags, ax=ax[1])\n",
        "ax[1].set_title('PACF Plot (Number of Tornadoes)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eixVl9fDJyAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the ARIME model with parameters p, d, q\n",
        "model = ARIMA(yearly_data['num_tornadoes_diff'].dropna(), order=(1, 1, 1))\n",
        "model_fit = model.fit()\n",
        "\n",
        "print(model_fit.summary())"
      ],
      "metadata": {
        "id": "TRngyTY3GzkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot residuals of the fitted model to check if they resemble white noise\n",
        "residuals = model_fit.resid\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(residuals)\n",
        "plt.title('Residuals of ARIMA Model')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D9s6yZvnKpCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Forecast for the next 10 years based on the fitted ARIMA model\n",
        "forecast_steps = 10\n",
        "forecast = model_fit.forecast(steps=forecast_steps)\n",
        "forecast_years = np.arange(yearly_data.index.max() + 1, yearly_data.index.max() + forecast_steps + 1)\n",
        "\n",
        "#Plotting historical tornado data and forcasted tornadoes for the next 10 years\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(yearly_data.index, yearly_data['num_tornadoes'], label='Historical Tornadoes')\n",
        "plt.plot(forecast_years, forecast, label='Forecasted Tornadoes', color='red')\n",
        "plt.title('Tornado Forecast for the Next 10 Years')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J1syuLUeG2up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the ARIMA model using AIC and BIC metrics\n",
        "print(f\"AIC: {model_fit.aic}\")\n",
        "print(f\"BIC: {model_fit.bic}\")"
      ],
      "metadata": {
        "id": "2dkELMPsG65X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into training and testing sets for model validation\n",
        "train_size = int(len(yearly_data) * 0.8)\n",
        "train, test = yearly_data['num_tornadoes_diff'][:train_size], yearly_data['num_tornadoes_diff'][train_size:]\n",
        "\n",
        "#Fit the ARIMA model on training data and forecast on the test data\n",
        "p = 1\n",
        "d = 1\n",
        "q = 1\n",
        "model = ARIMA(train, order=(p, d, q))\n",
        "model_fit = model.fit()\n",
        "forecast = model_fit.forecast(steps=len(test))"
      ],
      "metadata": {
        "id": "_SJSPG8eLk0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the training data, test data, and forecasted values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(yearly_data.index[:train_size], train, label='Train', color='blue')\n",
        "plt.plot(yearly_data.index[train_size:], test, label='Test', color='green')\n",
        "plt.plot(yearly_data.index[train_size:], forecast, label='Forecast', color='red')\n",
        "plt.legend()\n",
        "plt.title('ARIMA Forecast vs Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G0gWd2jBNMpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate RMSE to evaluate model's accuracy\n",
        "rmse = mean_squared_error(test, forecast, squared=False)\n",
        "print(f\"RMSE: {rmse}\")"
      ],
      "metadata": {
        "id": "lEjxNwZ1L58C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying differencing if series is non-stationary (p-value > 0.05)\n",
        "if result[1] > 0.05:\n",
        "    yearly_data['loss_diff'] = yearly_data['loss'].diff().dropna()\n",
        "    result = adfuller(yearly_data['loss_diff'])\n",
        "    stationarity_interpretation = \"Stationary\" if result[1] < 0.05 else \"Non-Stationary\"\n",
        "\n",
        "else:\n",
        "    yearly_data['loss_diff'] = yearly_data['loss']\n",
        "    stationarity_interpretation = \"Stationary\"\n",
        "\n",
        "print(f\"ADF Statistic after differencing: {result[0]}\")\n",
        "print(f\"p-value after differencing: {result[1]}\")\n",
        "print(f\"Interpretation: The series is {stationarity_interpretation}.\")"
      ],
      "metadata": {
        "id": "10hrPz4GpDdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_lags = min(40, len(yearly_data['loss']) // 2)\n",
        "fig, ax = plt.subplots(2, figsize=(12, 8))\n",
        "\n",
        "#ACF plot to find 'q' (moving average term)\n",
        "plot_acf(yearly_data['loss'], lags=max_lags, ax=ax[0])\n",
        "ax[0].set_title('ACF Plot (Loss)')\n",
        "\n",
        "#PACF plot to find 'p' (autoregressive term)\n",
        "plot_pacf(yearly_data['loss'], lags=max_lags, ax=ax[1])\n",
        "ax[1].set_title('PACF Plot (Loss)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qCuzP1y6pNPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the ARIME model with parameters p, d, q\n",
        "model = ARIMA(yearly_data['loss'].dropna(), order=(1, 1, 1))\n",
        "model_fit = model.fit()\n",
        "\n",
        "print(model_fit.summary())"
      ],
      "metadata": {
        "id": "av99U99Ppefh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Forecast for the next 10 years based on the fitted ARIMA model\n",
        "forecast_steps = 10\n",
        "forecast = model_fit.forecast(steps=forecast_steps)\n",
        "forecast_years = np.arange(yearly_data.index.max() + 1, yearly_data.index.max() + forecast_steps + 1)\n",
        "\n",
        "#Plotting historical tornado data and forcasted tornadoes for the next 10 years\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(yearly_data.index, yearly_data['loss'], label='Past Loss')\n",
        "plt.plot(forecast_years, forecast, label='Forecasted Loss', color='red')\n",
        "plt.title('Loss Forecast for the Next 10 Years')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sYtjiLgppi4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the ARIMA model using AIC and BIC metrics\n",
        "print(f\"AIC: {model_fit.aic}\")\n",
        "print(f\"BIC: {model_fit.bic}\")"
      ],
      "metadata": {
        "id": "kg4SlB01p5Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into training and testing sets for model validation\n",
        "train_size = int(len(yearly_data) * 0.8)\n",
        "train, test = yearly_data['loss'][:train_size], yearly_data['loss'][train_size:]\n",
        "\n",
        "#Fit the ARIMA model on training data and forecast on the test data\n",
        "p = 1\n",
        "d = 1\n",
        "q = 1\n",
        "model = ARIMA(train, order=(p, d, q))\n",
        "model_fit = model.fit()\n",
        "forecast = model_fit.forecast(steps=len(test))"
      ],
      "metadata": {
        "id": "uWRYeQWxp6BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the training data, test data, and forecasted values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(yearly_data.index[:train_size], train, label='Train', color='blue')\n",
        "plt.plot(yearly_data.index[train_size:], test, label='Test', color='green')\n",
        "plt.plot(yearly_data.index[train_size:], forecast, label='Forecast', color='red')\n",
        "plt.legend()\n",
        "plt.title('ARIMA Forecast vs Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1IdSZAr3p-Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate RMSE to evaluate model's accuracy\n",
        "rmse = mean_squared_error(test, forecast, squared=False)\n",
        "print(f\"RMSE: {rmse}\")"
      ],
      "metadata": {
        "id": "mGFXm00QqMQx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}